"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[24],{4082:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>c,frontMatter:()=>i,metadata:()=>o,toc:()=>a});const o=JSON.parse('{"id":"seq-db/long-term-store","title":"Long term stores","description":"Problem","source":"@site/i18n/ru/docusaurus-plugin-content-docs/current/seq-db/07-long-term-store.md","sourceDirName":"seq-db","slug":"/seq-db/long-term-store","permalink":"/seq-db-docs/ru/seq-db/long-term-store","draft":false,"unlisted":false,"editUrl":"https://github.com/ozontech/seq-db/tree/main/website/docs/docs/seq-db/07-long-term-store.md","tags":[],"version":"current","sidebarPosition":7,"frontMatter":{},"sidebar":"docs","previous":{"title":"seq-ql","permalink":"/seq-db-docs/ru/seq-db/seq-ql"},"next":{"title":"Rate limiting requests","permalink":"/seq-db-docs/ru/seq-db/rate-limiting"}}');var r=s(4848),n=s(8453);const i={},l="Long term stores",d={},a=[{value:"Problem",id:"problem",level:2},{value:"Solution",id:"solution",level:2},{value:"Stores",id:"stores",level:2},{value:"Read stores",id:"read-stores",level:3},{value:"Write",id:"write",level:3},{value:"Querying",id:"querying",level:3},{value:"Avoid old docs in hot store",id:"avoid-old-docs-in-hot-store",level:3},{value:"Deploy",id:"deploy",level:2},{value:"First step",id:"first-step",level:3},{value:"Second step",id:"second-step",level:3},{value:"Third step",id:"third-step",level:3}];function h(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",ul:"ul",...(0,n.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.header,{children:(0,r.jsx)(t.h1,{id:"long-term-stores",children:"Long term stores"})}),"\n",(0,r.jsx)(t.h2,{id:"problem",children:"Problem"}),"\n",(0,r.jsx)(t.p,{children:"Currently seq-db is using SSD storage to ensure good performance for users.\nBut SSD storage is limited, so we can't store a lot of historical data.\nAt the same time a small number of requests want to get historical data\nfor a long period of time."}),"\n",(0,r.jsx)(t.h2,{id:"solution",children:"Solution"}),"\n",(0,r.jsx)(t.p,{children:"Natural solution to this is to introduce long term (cold) stores with\nlarge storage (possibly HDD). So, data should be written to both types of\nstores. Most reads go to hot store, but reads for long periods should go\nto long term stores."}),"\n",(0,r.jsx)(t.h2,{id:"stores",children:"Stores"}),"\n",(0,r.jsx)(t.p,{children:"Ingestor knows several types of stores:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"hot stores (always used for write, used for search only if hot read stores are not enabled)"}),"\n",(0,r.jsx)(t.li,{children:"hot read stores"}),"\n",(0,r.jsx)(t.li,{children:"long term (cold) stores (always used for write, used for search only if cold read stores are not enabled)"}),"\n",(0,r.jsx)(t.li,{children:"long term (cold) read stores"}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"read-stores",children:"Read stores"}),"\n",(0,r.jsx)(t.p,{children:"Read mode of stores is needed for migration."}),"\n",(0,r.jsx)(t.p,{children:"Since write operation fails on single write failure it is necessary to exclude machine to be migrated from the write list.\nIt is done by enabling read stores (hot/cold respectively). If read stores are set, querying is done only through them and\nregular stores continue to be used only for write."}),"\n",(0,r.jsxs)(t.p,{children:["Thus to move a regular (hot/cold) store ",(0,r.jsx)(t.code,{children:"M"})," to another machine the pattern is:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"enable read stores (move all stores to be queried to the read list, including M)"}),"\n",(0,r.jsx)(t.li,{children:"exclude M from regular list"}),"\n",(0,r.jsx)(t.li,{children:"restart ingestor"}),"\n",(0,r.jsx)(t.li,{children:"shutdown M. Since M is excluded from write, write operations will not fail"}),"\n",(0,r.jsx)(t.li,{children:"migrate store"}),"\n",(0,r.jsx)(t.li,{children:"disable read stores, return M to regular list"}),"\n",(0,r.jsx)(t.li,{children:"restart ingestor"}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"write",children:"Write"}),"\n",(0,r.jsx)(t.p,{children:"When data is written (bulk send), it is first sent to hot stores, then to cold stores. Error in writing to any of them results an overall error.\nCurrently data can be saved in long term store, but not in hot (TODO: fix)."}),"\n",(0,r.jsx)(t.h3,{id:"querying",children:"Querying"}),"\n",(0,r.jsx)(t.p,{children:"On search hot stores are queried first."}),"\n",(0,r.jsxs)(t.p,{children:["Hot stores refuse to search if ",(0,r.jsx)(t.code,{children:"From"})," field is less than the oldest MID on this store\n(it means search may ask for data that is already rotated on the store). Ingestor\nreceives an error and in case it has long term stores configured, queries them.\nBoth hot and cold store can return partial response, and it will be considered valid.\nFor now there are no error type checking because it is not trivial for GRPC,\nthis will be implemented in the future."]}),"\n",(0,r.jsx)(t.h3,{id:"avoid-old-docs-in-hot-store",children:"Avoid old docs in hot store"}),"\n",(0,r.jsx)(t.p,{children:"There is a problem that a doc with very old timestamp may be submitted to hot store.\nThis doc will have very low seq.MID and sooner or later it will become the oldest\nMID in the store. This will result a behavior that hot store will answer to wider\nrange of queries, when normally they should be sent to long term store."}),"\n",(0,r.jsx)(t.p,{children:"To avoid this need to make an important change to bulk process. There is now a special check of time field\nand three possible outcomes:"}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsx)(t.li,{children:"Time field exists and has a correct value (not older than 24h from now):\nin this case no changes to doc and seq.MID calculated from this value."}),"\n",(0,r.jsx)(t.li,{children:"Time field does not exist: doc is not changed, seq.MID calculated\nfrom time.Now()"}),"\n",(0,r.jsxs)(t.li,{children:["Time field holds very old value (more than 24h from now): in this\ncase doc is changed, value of time field is changed to time.Now(), seq.MID\nis calculated from that. Original timestamp is stored in field\n",(0,r.jsx)(t.code,{children:"original_timestamp"}),", this field is overwritten if exists."]}),"\n"]}),"\n",(0,r.jsx)(t.h2,{id:"deploy",children:"Deploy"}),"\n",(0,r.jsx)(t.p,{children:"As we don't have long term store right now, deploy will be done in several steps\nto avoid interruption of service."}),"\n",(0,r.jsx)(t.h3,{id:"first-step",children:"First step"}),"\n",(0,r.jsx)(t.p,{children:"Current stores become hot stores, but hot mode is not enabled. In this case\nbehavior is the same as in older code. This removes an option to have read/write\nstores separately, but it's necessary."}),"\n",(0,r.jsx)(t.h3,{id:"second-step",children:"Second step"}),"\n",(0,r.jsx)(t.p,{children:"This step may be done together with the first step. We create new stores with\nlarge storage and add them to ingestors as write-stores. Now ingestors write\ndata to both types of stores, but read queries will go to hot stores only.\nAfter that we need to wait for long term stores to have data at least for\nthe same period as hot stores."}),"\n",(0,r.jsx)(t.h3,{id:"third-step",children:"Third step"}),"\n",(0,r.jsx)(t.p,{children:"Now we can add all long term stores as read stores and enable hot store-mode\nfor hot stores. This effectively enables a new scheme, when hot store can return\nerror and query will go to read (long term) stores. As before, write stores should\nbe a subset of read stores."})]})}function c(e={}){const{wrapper:t}={...(0,n.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>i,x:()=>l});var o=s(6540);const r={},n=o.createContext(r);function i(e){const t=o.useContext(n);return o.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(n.Provider,{value:t},e.children)}}}]);