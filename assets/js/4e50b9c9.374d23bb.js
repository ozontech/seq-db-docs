"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[90],{1716:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>t,default:()=>h,frontMatter:()=>a,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"seq-db/internal/cache","title":"Cache overview","description":"Currently, cache system\'s responsibility is to optimize access to index on disk","source":"@site/docs/seq-db/internal/cache.md","sourceDirName":"seq-db/internal","slug":"/seq-db/internal/cache","permalink":"/seq-db-docs/seq-db/internal/cache","draft":false,"unlisted":false,"editUrl":"https://github.com/ozontech/seq-db/tree/main/website/docs/docs/seq-db/internal/cache.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docs","previous":{"title":"benchmarks","permalink":"/seq-db-docs/seq-db/benchmarks"},"next":{"title":"Basic moments","permalink":"/seq-db-docs/seq-db/internal/common"}}');var c=s(4848),r=s(8453);const a={},t="Cache overview",o={},d=[{value:"Layer sizes",id:"layer-sizes",level:3},{value:"Entries",id:"entries",level:3},{value:"Generations",id:"generations",level:3},{value:"Cleaning",id:"cleaning",level:3}];function l(e){const n={a:"a",code:"code",h1:"h1",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",ul:"ul",...(0,r.R)(),...e.components};return(0,c.jsxs)(c.Fragment,{children:[(0,c.jsx)(n.header,{children:(0,c.jsx)(n.h1,{id:"cache-overview",children:"Cache overview"})}),"\n",(0,c.jsx)(n.p,{children:"Currently, cache system's responsibility is to optimize access to index on disk\nby storing in memory recently accessed data, as to avoid excess reads.\nData is stored in most cases in near-raw format, just after unpacking."}),"\n",(0,c.jsx)(n.p,{children:"Core concepts:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"cache.Cache"}),": single cache instance, mimicking generic map with uint32 keys;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"cache.bucket"}),": interface, implemented by ",(0,c.jsx)(n.code,{children:"Cache"})," and used by ",(0,c.jsx)(n.code,{children:"Cleaner"}),";"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"cache.Cleaner"}),": keeps collection of ",(0,c.jsx)(n.code,{children:"bucket"}),"s, implements cleaning"]}),"\n",(0,c.jsx)(n.li,{children:"layer: type of data we are to cache. There's six different layers;"}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"frac.SealedIndexCache"}),": one for a fraction. Keeps together ",(0,c.jsx)(n.code,{children:"Cache"})," instances\nfor this fraction, one per layer;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"fracmanager.CacheMaintainer"}),": keeps all ",(0,c.jsx)(n.code,{children:"Cleaner"}),"s, is responsible\nfor maintaining size, logging and creating new ",(0,c.jsx)(n.code,{children:"SealedIndexCache"}),"s."]}),"\n"]}),"\n",(0,c.jsx)(n.p,{children:"Overall, there are two parallel layouts."}),"\n",(0,c.jsxs)(n.p,{children:["First, every fraction has its own ",(0,c.jsx)(n.code,{children:"SealedIndexCache"}),", which holds reference\nto all related ",(0,c.jsx)(n.code,{children:"Cache"})," instances, allowing fraction (and its substructures)\naccess to cache, and to stored on disk index through it."]}),"\n",(0,c.jsxs)(n.p,{children:["Second, ",(0,c.jsx)(n.code,{children:"FracManager"})," holds reference to ",(0,c.jsx)(n.code,{children:"CacheMaintainer"})," which performs all\nthe maintenance through respective ",(0,c.jsx)(n.code,{children:"Cleaner"}),"s. Each ",(0,c.jsx)(n.code,{children:"Cleaner"})," not necessarily\nrepresent single layer, though every layer is maintained by one ",(0,c.jsx)(n.code,{children:"Cleaner"}),"."]}),"\n",(0,c.jsxs)(n.p,{children:["Package ",(0,c.jsx)(n.code,{children:"cache"})," is implemented independently of other packages,\nwith encapsulation in mind."]}),"\n",(0,c.jsxs)(n.p,{children:["On the other hand, ",(0,c.jsx)(n.code,{children:"SealedIndexCache"})," and ",(0,c.jsx)(n.code,{children:"CacheMaintainer"})," bind it to\nour layers, limits and workflow."]}),"\n",(0,c.jsx)(n.h1,{id:"cache-layers",children:"Cache layers"}),"\n",(0,c.jsxs)(n.p,{children:["See ",(0,c.jsx)(n.a,{href:"/seq-db-docs/seq-db/internal/format-index-file",children:"Index File Format"}),"."]}),"\n",(0,c.jsx)(n.p,{children:"There are 7 cache layers:"}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"index"}),": also called ",(0,c.jsx)(n.code,{children:"Registry"}),", contains information on the fraction index\nfile layout;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"tokens"}),": all the tokens from all the indexed fields in docs in fraction;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"lids"}),": for every token list of lids that match it;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"docsdocblock"}),": for docblocks read during Fetch;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"mids"}),", ",(0,c.jsx)(n.code,{children:"rids"}),", ",(0,c.jsx)(n.code,{children:"params"}),": mid, rid and position (docs block index, doc offset)\nof every lid, allowing to identify and locate corresponding doc."]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"Cache"})," instances related to same layer are maintained by the same ",(0,c.jsx)(n.code,{children:"Cleaner"}),".\nThere are currently 5 of them in ",(0,c.jsx)(n.code,{children:"CacheMaintainer"}),":"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"lids"})," cleaner: this one is responsible for instances related to ",(0,c.jsx)(n.code,{children:"lids"})," layer;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"tokens"})," cleaner: same for ",(0,c.jsx)(n.code,{children:"tokens"})," layer;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"index"})," cleaner: same for ",(0,c.jsx)(n.code,{children:"index"})," layer;"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"docblock"})," cleaner: same for ",(0,c.jsx)(n.code,{children:"docblock"})," layer"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"mids-rids-params"})," cleaner: this one takes care of other layers, i.e. ",(0,c.jsx)(n.code,{children:"mids"}),", ",(0,c.jsx)(n.code,{children:"rids"})," and ",(0,c.jsx)(n.code,{children:"params"}),"."]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:["They are separated this way due to their relative loads. ",(0,c.jsx)(n.code,{children:"lids"})," have very big\nvalues and are accessed often. ",(0,c.jsx)(n.code,{children:"tokens"})," instead have very big amount of small\nvalues, and are accessed often too. Other layers do not match, and thus can be\ncombined as to provide some basic level of protection against being purged by\n",(0,c.jsx)(n.code,{children:"lids"})," or ",(0,c.jsx)(n.code,{children:"tokens"}),", which in turn require protection from each other."]}),"\n",(0,c.jsx)(n.h3,{id:"layer-sizes",children:"Layer sizes"}),"\n",(0,c.jsxs)(n.p,{children:["Layers don't have prefixed sizes. Instead, each ",(0,c.jsx)(n.code,{children:"Cleaner"})," is associated with\nsize restriction. Restrictions are measured in fraction of total cache size:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"lids"}),": 40%"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"tokens"}),": 40%"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"docblock"}),": 8%"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"index"}),": 3%"]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"mids-rids-params"}),": 9%"]}),"\n"]}),"\n",(0,c.jsx)(n.h1,{id:"interface",children:"Interface"}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"Cache"})," has one basic access method, that being ",(0,c.jsx)(n.code,{children:"Get"}),".\nIt takes the key and the factory function that will be called to create\nnew value if the key is not present. The value type is generic."]}),"\n",(0,c.jsxs)(n.p,{children:["The second access method is ",(0,c.jsx)(n.code,{children:"GetWithError"}),". This one allows factory function\nto return error instead of value, which will not be saved in cache,\nbut passed through."]}),"\n",(0,c.jsxs)(n.p,{children:[(0,c.jsx)(n.code,{children:"Cache"})," can store any type of values inside, and ",(0,c.jsx)(n.code,{children:"SealedIndexCache"}),"\nholds the exact instances, specialized for layer-related structures."]}),"\n",(0,c.jsx)(n.h1,{id:"internals",children:"Internals"}),"\n",(0,c.jsxs)(n.p,{children:["Current implementation has one ",(0,c.jsx)(n.code,{children:"mu sync.Mutex"})," for each ",(0,c.jsx)(n.code,{children:"Cache"})," instance,\nserving as a global lock. Under protection of this lock atomic operations\nare performed, accessing and modifying the data."]}),"\n",(0,c.jsx)(n.p,{children:"Simple access to cache is designed to take lock only for brief periods of time.\nSome other whole-cache-related operations, like getting stats or cleaning,\nare allowed to take lock for longer times, given this doesn't trouble\nsimple accesses."}),"\n",(0,c.jsx)(n.p,{children:"In most cases access requires only one such period. Adding new value\nto the cache takes two though. Creation of the corresponding value takes time,\nand thus we only need lock in the beginning and in the end. Rarely,\nin case of panics (or returned error) in provided factory function,\nit can take more lock/unlock cycles."}),"\n",(0,c.jsxs)(n.p,{children:["Data is stored in ",(0,c.jsx)(n.code,{children:"entry"})," objects, which are referenced from\n",(0,c.jsx)(n.code,{children:"payload map[uint32]*entry[V]"}),". Entries are organized into generations as to\nfacilitate cache cleaning process. ",(0,c.jsx)(n.code,{children:"generations []*Generation"})," are thus\nstored in ",(0,c.jsx)(n.code,{children:"Cleaner"})," instances for this purpose."]}),"\n",(0,c.jsx)(n.h3,{id:"entries",children:"Entries"}),"\n",(0,c.jsxs)(n.p,{children:["Internally, cache operates on ",(0,c.jsx)(n.code,{children:"entry"})," objects, which represent stored\n",(0,c.jsx)(n.code,{children:"value V"})," with some cache-related information:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"wg *sync.WaitGroup"}),". This one is of most importance, as it is used to\nwait for value creation, and indicates whether it was successful.\nIt's initialized with ",(0,c.jsx)(n.code,{children:"Add(1)"}),"."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"gen *generation"})," links entry to its generation.\n",(0,c.jsx)(n.code,{children:"nil"})," until ",(0,c.jsx)(n.code,{children:"value"})," is loaded. The only one that keeps changing and\ncannot be accessed without lock even when ",(0,c.jsx)(n.code,{children:"wg"})," is ",(0,c.jsx)(n.code,{children:"nil"})," or waited on."]}),"\n",(0,c.jsxs)(n.li,{children:[(0,c.jsx)(n.code,{children:"size"})," contains size of the loaded value."]}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:["All entry changes are done under ",(0,c.jsx)(n.code,{children:"Cache.mu"})," lock, and between locks\neach entry can be in one of the following states:"]}),"\n",(0,c.jsxs)(n.ol,{children:["\n",(0,c.jsx)(n.li,{children:"Not present. There's no value nor entry for this key,\nas it wasn't accessed since cache creation, or was cleared."}),"\n",(0,c.jsxs)(n.li,{children:["Entry is present, ",(0,c.jsx)(n.code,{children:"wg"})," is not ",(0,c.jsx)(n.code,{children:"nil"}),", but ",(0,c.jsx)(n.code,{children:"Done()"})," wasn't yet called.\nIt means that this key was recently accessed,\nand the value for it is being created right now.\nThere may be some pending accesses that wait on ",(0,c.jsx)(n.code,{children:"wg"}),".\n",(0,c.jsx)(n.code,{children:"gen"})," and ",(0,c.jsx)(n.code,{children:"size"})," are not initialized."]}),"\n",(0,c.jsxs)(n.li,{children:["Entry is present, ",(0,c.jsx)(n.code,{children:"wg"})," is ",(0,c.jsx)(n.code,{children:"nil"}),".\nThis means the entry is valid, and ",(0,c.jsx)(n.code,{children:"value"})," can be returned.\n",(0,c.jsx)(n.code,{children:"gen"})," and ",(0,c.jsx)(n.code,{children:"size"})," have correct values."]}),"\n",(0,c.jsxs)(n.li,{children:["Entry has ",(0,c.jsx)(n.code,{children:"wg"}),", ",(0,c.jsx)(n.code,{children:"Done()"})," was already called.\nThis indicates that entry is invalid. In this case it's not present\nin ",(0,c.jsx)(n.code,{children:"payload"})," map and exists only because someone may be waiting on it.\nEntry gets into this state if the function responsible for value creation\nhas panicked, or returned error. The entry was then marked as invalid\nand removed, and is to be created again by someone else.\n",(0,c.jsx)(n.code,{children:"gen"})," and ",(0,c.jsx)(n.code,{children:"size"})," are both not initialized.\nEveryone waiting on this ",(0,c.jsx)(n.code,{children:"wg"})," should reattempt access, possibly creating\nnew entry themselves."]}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"generations",children:"Generations"}),"\n",(0,c.jsxs)(n.p,{children:["For the cleaning purposes, all entries are linked to some generation,\nwhich was stored in ",(0,c.jsx)(n.code,{children:"Cache.currentGeneration"})," at the moment of such ",(0,c.jsx)(n.code,{children:"entry"}),"\nbecoming valid or last accessed, whichever happens later.\nEntries that are not yet valid don't have generation."]}),"\n",(0,c.jsxs)(n.p,{children:["All generation-related operations are performed under ",(0,c.jsx)(n.code,{children:"Cache.mu"})," lock.\nBetween locks, all ",(0,c.jsx)(n.code,{children:"generation"})," objects are in one of the three states:"]}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsxs)(n.li,{children:["Current generation. There's always one and only one such generation.\nThat one is stored in every accessed ",(0,c.jsx)(n.code,{children:"entry"}),"."]}),"\n",(0,c.jsx)(n.li,{children:"Non-current and non-stale generation. Most generations are in this state.\nThe values linked to these generations were accessed recently enough to\nbe protected from clearing."}),"\n",(0,c.jsx)(n.li,{children:"Stale. This state is for generations that are considered old, but were not yet\ncleaned because they weren't considered big enough."}),"\n"]}),"\n",(0,c.jsx)(n.h3,{id:"cleaning",children:"Cleaning"}),"\n",(0,c.jsx)(n.p,{children:"Cleaning consists of two independent process. First one is periodical creation\nof new generations, and the second one is periodical marking generations\nas stale and consequent cleaning of them."}),"\n",(0,c.jsxs)(n.p,{children:["Each ",(0,c.jsx)(n.code,{children:"Cleaner"})," instance has set of generations. New generations are created\n",(0,c.jsx)(n.code,{children:"Cleaner"}),"-wide when some known amount (say, 10% of the limit) of new data was stored.\nAt this moment every ",(0,c.jsx)(n.code,{children:"Cache"})," instance is instructed to use new generation as current,\nthus sealing the last one."]}),"\n",(0,c.jsxs)(n.p,{children:["When the ",(0,c.jsx)(n.code,{children:"Cleaner"})," decides that it has started to exceed its memory limit, it marks the\noldest few generations, which together are large enough to free up memory, as stale.\nIt then initiates the removal of all stale generations entries from each ",(0,c.jsx)(n.code,{children:"Cache"}),"."]}),"\n",(0,c.jsxs)(n.p,{children:["Also time to time ",(0,c.jsx)(n.code,{children:"Cleaner"})," finds released ",(0,c.jsx)(n.code,{children:"Cache"}),"s and removes it from list as well\nas empty generations."]}),"\n",(0,c.jsx)(n.h1,{id:"metrics",children:"Metrics"}),"\n",(0,c.jsx)(n.p,{children:"There are several metrics collected as to check cache health.\nEach metric is collected separately for each layer."}),"\n",(0,c.jsxs)(n.ul,{children:["\n",(0,c.jsx)(n.li,{children:"HitsTotal - access counter, when value was present"}),"\n",(0,c.jsx)(n.li,{children:"MissTotal - access counter, when value was inserted by accessor"}),"\n",(0,c.jsx)(n.li,{children:"MissLatency - counter of seconds me spend getting data when we miss cache"}),"\n",(0,c.jsx)(n.li,{children:"PanicsTotal - access counter, when value wasn't inserted by accessor"}),"\n",(0,c.jsx)(n.li,{children:"LockWaitsTotal - number of times initial lock for simple access\nwasn't acquired immediately, thus forcing rescheduling"}),"\n",(0,c.jsx)(n.li,{children:"WaitTotal - number of times access method had to wait for someone else to\nput value into cache"}),"\n",(0,c.jsx)(n.li,{children:"ReattemptsTotal - number of times access method had to reattempt due to entry\ninvalidation"}),"\n",(0,c.jsx)(n.li,{children:"SizeOccupied - counter of size of the values added to cache on miss"}),"\n",(0,c.jsx)(n.li,{children:"SizeRead - counter of size of the values retrieved on hit"}),"\n",(0,c.jsx)(n.li,{children:"SizeReleased - counter of size of data we released"}),"\n",(0,c.jsx)(n.li,{children:"MapsRecreated - counter of events we recreate cache maps"}),"\n"]}),"\n",(0,c.jsxs)(n.p,{children:["As a rule, ",(0,c.jsx)(n.code,{children:"TouchTotal = HitsTotal + MissTotal + PanicsTotal"}),".\nAlso ",(0,c.jsx)(n.code,{children:"TotalSize = SizeOccupied - SizeReleased"}),".\nMissTotal and SizeOccupied are the metrics to optimize cache.\nHitsTotal and SizeRead are the metrics to optimize cache use.\nRising WaitTotal means concurrent access to the same not-yet-cached value."]}),"\n",(0,c.jsx)(n.p,{children:"LockWaitsTotal ideally should be near-zero at all times and\nshows cache internal efficiency in terms of concurrent access. This is the one\nto check when implementing whole-cache-related operations.\nPanicsTotal and ReattemptsTotal ideally should be near-zero at all times and\nshow problems with cache usage."})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,c.jsx)(n,{...e,children:(0,c.jsx)(l,{...e})}):l(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>t});var i=s(6540);const c={},r=i.createContext(c);function a(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(c):e.components||c:a(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);